{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Count\n",
    "Counting the ocurrence of words among all the articles appearing on a given day."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import the text file to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This imports the file which has the URLs to the article run \"df\" to visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../guardian_opinions_scrape/opinions.csv')\n",
    "# df.head(5)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go to URL & Read"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "\n",
    "for i,url in df['url'].items():\n",
    "    article = requests.get(url)\n",
    "    soup = BeautifulSoup(article.text, 'html.parser')\n",
    "    articles.append(soup.find('div', {'id': \"maincontent\"}).find_all('p', {'class': \"dcr-1bfjmfh\"}))\n",
    "    \n",
    "for article in articles:\n",
    "    soup = BeautifulSoup(str(article), 'html.parser')\n",
    "\n",
    "    for i in soup.find_all(['span','a','p']):\n",
    "        i.unwrap()\n",
    "        \n",
    "    with open('clean_text.txt', 'a') as file:\n",
    "            file.write(str(soup))    \n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaning the text from obvious extraneous characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clean_text.txt', 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "    data = data.replace('[', \"\")\n",
    "    data = data.replace(']', \"\")\n",
    "    data = data.replace('., ', \". \")\n",
    "\n",
    "with open('clean_text.txt', \"w\") as file:\n",
    "    file.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
